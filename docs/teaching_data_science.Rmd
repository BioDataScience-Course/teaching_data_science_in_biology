---
title: "Teaching Data Science to Undergraduate and Graduate Students in Biology using R, RStudio and Learnr: Analysis of Three Years Data Including COVID-19 Pandemic Lockdowns"
output: 
  html_document:
    code_folding: hide
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
SciViews::R

# datasets

users18 <- read(pcloud("sdd_2018-2019/data/users.csv")) 
users19 <- read(pcloud("sdd_2019-2020/data/users.csv")) 
users <- read(pcloud("sdd_2020-2021/data/users.csv")) 

assessments18 <- read(pcloud("sdd_2018-2019/data/assessment_temp.csv"))

exam19 <- read(pcloud("sdd_2019-2020/data/exam.csv")) 
assessments19 <- read(pcloud("sdd_2019-2020/data/assessment.csv"))

courses18 <- read(pcloud("sdd_2018-2019/data/courses.csv")) 
courses19 <- read(pcloud("sdd_2019-2020/data/courses.csv")) 
courses <- read(pcloud("sdd_2020-2021/data/courses.csv")) 

assessments <- read(pcloud("sdd_2020-2021/data/assessments.csv"))
learnr <- read(pcloud("sdd_2020-2021/data/learnr.csv"))
projects <- read(pcloud("sdd_2020-2021/data/projects.csv")) %>.%
  mutate(., 
    icourse = course,
    course = substr(github_project, 1,1),
    type = case_when(
      subtype == "individual" ~ "ind. github",
      subtype == "group" ~ "group github",
      subtype == "challenge,group" ~ "challenge"))

wo <- read(pcloud("sdd_2020-2021/data/wooclap.csv"))

# functions ----
## RTLX NASA - TLX -------------------------------------------------------------
learnr_feeling <- function(df, apps, labels) {
  res <- dplyr::filter(df, app == apps & label == labels)
  
  c("(\\d):(Quelle a été l'importance de l'activité mentale et intellectuelle requise)", 
    "(\\d):(Quelle a été l'importance de l'activité physique requise)",
    "(\\d):(Quelle a été l'importance de la pression temporelle causée par la rapidité nécessitée pour l'accomplissement de la tâche)",
    "(\\d):Quelle réussite pensez-vous avoir eu dans l'accomplissement de la tâche",
    "(\\d):Quel degré d'effort avez-vous dû fournir pour exécuter la tâche demandée",
    "(\\d):Pendant l'exécution du travail vous êtes-vous senti découragé"
    ) %>.%
  purrr::map_dfc(., function(str, pattern) {stringr::str_match(str, pattern = pattern)[,2]}, str = res$value) -> vec
  
  names(vec) <- c("mental", "physical", "time_pressure", "performance", "effort", "frustration")
  
  vec %>.%
    map_dfc(.,as.numeric) -> vec1
  
  vec1$app <- apps
  vec1$label <- labels
  vec1$user <- res$user
  return(vec1)
}


n_fun <- function(x){
  return(data.frame(y = max(x) * 1.1, label = paste0("n = ",length(x))))
}
```

# Abstract 

**This is the original abstract that should be reworked according to final content of the manuscript.**

The courses in biostatistics in biology at the University of Mons, Belgium, were completely refactored in 2018 into data science courses (see http://bds.sciviews.org). The content is expanded beyond statistics to include computing tools, version management, reproducible analyses, critical thinking and open data. Flipped classroom approach is used. Students learn with the online material and they apply the concepts on individual and group projects using a preconfigured virtual machine with R and RStudio. Activities (H5P, learnr or Shiny applications) are recorded in a MongoDB database (300,000+ events for 180+ students and 2,000+ GitHub repositories at https://github.com/BioDataScience-Course). The analysis of these data reveals several trends. (1) There is a relatively long lag period required for the students to get used to the computing environment, the teaching method and the data science in general. (2) Implication is very high, with more than 85% of the students that complete all the activities and got good to excellent assessment. (3) There is a gap between students' own perception of their skills achievements and their assessment results: they tend to underestimate their progress. (4) During COVID-19 pandemic lockdown, the intensity of the activities largely decreased during two weeks before returning to previous level, but for 3/4 of the students only. The remaining fraction never caught up. We hypothesize that the technical requirements or the lack of motivation during the lockdown were detrimental to roughly one student over ten, despite all the efforts the University deployed to reduce the social fracture.


# Introduction

In a context where there is an exponentially growing mass of data [ref...], a reproducibility crisis in Science [@Baker2016], and a progressive adoption of Open Science practices [refs...], statistics were broaden to a larger discipline called data science. [may be put here the definition of data science we consider in the MS, with citation...] These changes also led to the emergence of data science programs in universities and higher schools. One example is the Harvard Data Science initiative (<https://datascience.harvard.edu/about>) initiated in 2015 [@Donoho2017; @Cetinkaya-Rundel2021]. With a broader approach, comes also a broaden public. The data science courses are not just limited to computer scientists, mathematicians or statisticians, but also welcome students in humanities, social sciences, and natural sciences (for instance, the data science training at Duke University [@Cetinkaya-Rundel2021]). Main focus of such courses is for students to develop the ability to deal with "real" datasets in all their complexities and to realize reproducible analyses to interpret these data in the light of knowledge in their field of expertise.

The data management part of the job is a challenge for students with a poor or no background at all in computing. Students that are not used to deal with computer languages enter in a foreign world and have to deal with many exotic concepts, techniques and tools. This generates anxiety (see for instance [@Onwuegbuzie2003], for students in biology). The course must be organized in a way that such students progress by little steps in order to avoid exposition to much intimidating concepts and tools at once. Hence, a student in computing science already masters one or more computing languages, is acquainted with version control systems, with databases and with the way data are represented in a computer. A student in mathematics or statistics is familiar with various concept that underpin the techniques to analyse the data. On the other hand, students in biology, medicine, psychology, social sciences, economics, ... have very different *a priori* knowledges. 

[TODO: to write this section] Teaching of git & GitHub, R Markdown and projects management integrated in data science courses. Git offers the double advantage to track changes in student's projects, and to teach them one valuable tool they will use in their future career.

Suitable computer hardware and software environments are required in the practical sessions of these courses. Different approaches range from inline software (RStudio Cloud, Chromebook data science) to local installation on the Student's computers. The later raises problems of license for proprietary software, but also installation and configuration issues. An intermediary solution uses preconfigured virtual machines, or containers (e.g., Docker) [refs]. This allows to play with the concepts and work on the various projects anywhere (in the computer lab, at home, uing a laptop, ...). To fix theoretical concepts through applied exercises is a key aspect of learning data science [@Larwin2011] [also cite Cetinkaya-rundel2017]. Correct choice of software is critical and exposing students early with the tools they are most susceptible to use later in their work is desirable. This was highlighted by [@Auker2020] for instance, for the analysis of ecological data.

These data science course represent thus several challenges to pedagogy because various, numerous and unfamiliar concepts must be acquired by a population of potentially very diverse students. Learning objectives span a large range of cognitive abilities (in the sens of Bloom's taxonomy, from remembering to creating, [ref krathwohl2010]). [explain here in 2-3 sentences main approaches used in these courses + refs]. [main points are: active pedagogy, development of student's automnomy in flipped classrooms, continuous evaluation and project pedagogy.] The flipped classroom approach allows students to be active in their learning, which has the benefit of improving student outcomes [@Freeman2014].

Recently, data science is also used to analyze the effect of different pedagogical practices on the outcome of these courses [ref Data Science in Education with R]. With numerical tools, a vast amount of data can be collected on students activities, and the analysis of these data allows to compare the impact of different pedagogical approaches, or to quantify and document the impact of changes in the courses.

At the University of Mons, in Belgium, we have started to rework our biostatistics courses in the biology curriculum in 2018. A series of Data Science courses were introduced, both for our undergraduate and graduate students. These courses are inspired from precursor initiatives cited here above. The goal of these courses is to form biological data scientists capable to extract meaningful information from raw biological data, and to do so in a reproducible way and with correct application of statistical tools and an adequate critical mindset. A preconfigured VirtualBox virtual machine with R, RStudio, Rmarkdown (Baumer2014), git, and a series of R packages preinstalled is used, as a very flexible way to deploy the same software environment both on the university computers and on student's own laptops.

As our course were completely reworked, we also decided to use flipped classroom and progressive adoption of suitable pedagogical practices with a cyclical approach that consists in stating goals, building pedagogical material with a large emphasis on numerical tools and collection of student's activities, and analysis of these data. Conclusions of these analyses initiate another cycle the following academic year with refined goals and pedagogical material or techniques. Here, we present the main results spanning on three successive academic years from 2018 to 2021, including two particular periods where distance learning was forced due to COVID pandemic lockdowns. 

[TODO: present here the 3-4 research questions that will be elaborated in the manuscript.]


# Material and methods

| Niveau | description                                                                         | type d'exercices |
|--------|-------------------------------------------------------------------------------------|------------------|
| N1     | Exercice court intégré directement dans le cours en ligne avec un feedback immédiat | h5p, shiny       |
| N2     | Exercice guidé dans un tutoriel avec un feedback immédiat                           | learnr           |
| N3     | Exercice cadré sous la forme d'un projet individuel                                 | ind github       |
| N4     | Exercice libre sous la forme de projet de groupe                                    | group github     |

ajouter une colonne avec la taxonomie de bloom 

The NASA-LTX indicator is composed of six questions on a Likert scale to quantify the perceived workload to complete a tutorial [@Hart1988]. The questions concern mental load, physical load, time pressure, expected success, effort required, and frustration experienced during the accomplishment of the task. The average value for the six questions constitutes a Raw Task Load indeX (RTLX) [@Byers1989].

The SUS ....

rechercher une ref plus récente type meta analyse SUS et NASA LTX

# Results

Liste des idées :

-  
-
-
-

La transition du cours classique vers une cours en classe inversée a menée à l'intégration de nouveaux outils permettant de diversifier les types d'exercice proposés aux étudiants (tab M&M). Le tableau XX indique la répartition des exercices pour chauqe cours. La collecte des données pour chaque exercice permet de construire une note objective pour chaque étudiant. La note des étudiant est construite sur l'évaluation des 5 niveaux d'exerices complémentaires allant des exercices les plus simples (N1) aux exercices les plus complexes (N5). Une moyenne pondérée pour chaque niveau d'exercice est employée pour obtenir une note finale par cours.

```{r}
# Tab of number of users and number of exercices by type ----------------------
# users
users %>.%
  filter(., institution == "UMONS" & term == "Q1" & state == "regular") %>.%
  group_by(., course) %>.%
  summarise(., user = n()) %>.%
  ungroup(.) %>.%
  filter(., course != "D")-> us_tab

# learnr
learnr %>.% 
  filter(., !label %in% c("","C99La_avis") & !is.na(label)) %>.%
  mutate(., course = substr(app,1,1),
    app_label = paste0(app, label)) %>.%
  filter(., course %in% c("A", "B", "C")) %>.%
  group_by(., course) %>.%
  summarise(., app = length(unique(app)), questions = length(unique(app_label)))-> t 

# projects
projects %>.%
  filter(., type %in% c("ind. github", "group github") & course != "D") %>.%
  group_by(., course, type) %>.%
  count(.) %>.%
  pivot_wider(., names_from = "type", values_from = "n") -> projects_tab
    
  

# tab number of exercices by type ---
assessments %>.%
  mutate(., 
    app_type = paste0(app,"_",'type'),
    course = substr(app, start = 1, stop = 1),
    ) %>.%
  group_by(., course, type) %>.%
  summarise(., tot = length(unique(app_type)))  %>.%
  ungroup(.) %>.%
  pivot_wider(., names_from = "type", values_from = "tot") %>.%
  select(., course,  h5p, shiny, learnr, `ind. github`, `group github`, blog) -> exercice_tab

knitr::kable(left_join(us_tab, exercice_tab, by = c("course")))
```

blog a virer , shiny on cogite à la virer, ind.github error cours C, learnr ajouter nombre de question en ()

```{r}
assessments18 %>.%
  #select(., -coral_growth, result = biometry) %>.%
  mutate(., result = (biometry+coral_growth)/2, acad_year = "2018-2019") -> assess_result18
  
q1_18_regular <- left_join(rename(assess_result18, icourse = course), courses18) %>.%
  filter(., user %in% users18$user[users18$institution == "UMONS" & users18$term == "Q1" & users18$state == "regular"])

assessments19 %>.%
  group_by(., course, evaluation, github_project, project, user) %>.%
  summarise(., result = round(sum(score*weight),4)) %>.%
  filter(., evaluation == "Q1") %>.%
  left_join(exam19, .) %>.%
  replace_na(., list(result = 0)) %>.%
  mutate(., acad_year = "2019-2020")-> assess_result19

q1_19_regular <- left_join(rename(assess_result19, icourse = course), courses19) %>.%
  filter(., user %in% users19$user[users19$institution == "UMONS" & users19$term == "Q1" & users19$state == "regular"])

q1 <- bind_rows(
  select(q1_18_regular, user, acad_year, course, result, exam),
  select(q1_19_regular, user, acad_year, course, result, exam)
  )
#table(q1$link) /nrow(q1)
q1 %>.%
  cor.test(.$exam, .$result)
```

Jusqu'au premier quadrimestre 2019-2020, la note des étudiants était basé sur la réalisation d'un projet et d'un examen plus conventionnel réalisé lors de la période des examens. Une faible corrélation linéaire significative de 0.41 est obtenue entre la note de l'examen et la note obtenu pour les projets (Pearson correlation test, t = 3.82, df = 74, p-value = 0.0002). 

La pandémie de COVID 19 nous a contraints à annuler l'examen du second quadrimestre 2019-2020 et d'évaluer uniquement les étudiants sur les projets. La faible corrélation entre la note du projet pratique et la note de l'examen observé lors du premier quadrimestre met en avant que la critère d'évaluation entre un projet pratique et un examen théorique ne sont pas les mêmes. Suite à cette observation, l'examen théorique est définitivement abandonné pour l'année académique 2020-2021.

```{r}
q1 %>.%
  mutate(., course_year = paste0(course, " (",acad_year,")")) %>.%
  chart(., exam ~ result %col=% user | course_year) +
  geom_vline(xintercept = 5, alpha = 0.2) +
  geom_hline(yintercept = 5, alpha = 0.2) +
  geom_jitter(alpha = 1, width = 0.05, height = 0.05, show.legend = FALSE) +
  ylim(c(0,10)) +
  xlim(c(0,10)) +
  labs(y = "Exam grade", x = "Project grade")
```

```{r}

```

on souhaite former des étudiants capable d'appliquer la science des données. L'examen plus classique ne ermet pasd'évaluer correctemetn les acquis pratique des étudiants. 

a exam in the end of the term, melange entre des questions théoriques et la mise en pratique.

```{r}
q1 %>.%
  filter(., course == "A") %>.%
  wilcox.test(data = ., exam ~ acad_year)
```


Le suivi de l'activité permet de mettre en avant différents profils d'étudiants. ....

```{r}
# TODO
```

La perception positives des étudiants face aux outils utilisés est un éléments important ...

```{r}
#SUS
```

La charge cognitive requise pour réaliser des tutoriel (N3) est étudié via un questionnaire NASA LTX. En effet, ces exercices ont pour objectif de permettre une transition plus facile de la théorie vers les exercices pratiques (N4 et N5).

```{r}
c("A99Wa_perception", "B99Wa_perception", "C99Wb_perception:perception") %>%
  purrr::map_dfr(learnr_feeling, df = wo, label = "Q4") %>.%
  mutate(., course = substr(app, start = 1, stop = 1)) -> learnr_workload

learnr_workload %>.%
  pivot_longer(.,cols = c(mental, physical, time_pressure, performance, effort, frustration),
  names_to = "category", values_to = "grade")  %>.%
  left_join(., dplyr::distinct(courses, course,name), by = "course")-> workload

workload %>.%
  group_by(., user, app, course) %>.%
  summarise(., rtlx = 10*mean(grade)) -> workload_rtlx

set.seed(222)
chart(workload_rtlx, rtlx ~ course) +
  geom_boxplot(fill = "#00BFC4") +
  geom_jitter(alpha = 0.5, width = 0.1) +
  labs(y = "RTLX", x = "Course") +
  stat_summary(fun.data = n_fun, geom = "text", hjust = 0.5) +
  labs( y = "Raw Task Load indeX (2020-2021)")
```

La difficultés des exercices tutoriels est croissante de cours en cours. Cependant, on observe une valeur du RTLX du cours de sciences des données 3 significativement plus faible que pour le cours de science des données 1 (Tukey HSD, p-value = 0.023). La charge cognitive percue par les étudiants est donc plus faible.

faire un test sur les médianes ....

```{r}
workload_rtlx %>.%
  mutate(., course = as.factor(course)) -> workload_rtlx

anova. <- lm(data = workload_rtlx, rtlx ~ course)
anova(anova.)

#bartlett.test(data = workload_rtlx, rtlx ~ course)
#plot(anova., which = 2)

summary(anovaComp. <- confint(multcomp::glht(anova.,
  linfct = multcomp::mcp(course = "Tukey"))))
```

La temporalité ....


# Discussion

Les études portant sur le changements d'attitudes au sein de semestre ne montre pas différence significative. La comparaison entre les 3 cours met en avant qu'il faut plusieurs cours en continue afin d'observer une chagement de la charge cognitive des étudiants.

apprentissage en continu sur 3 années successives (cohérence entre le programme et l'approche pédagogique), les résultats sont meilleurs vers la 3ieme années.

# Conclusions

- Exam classique évalue mal la capacité d'evaluer des données biologiques par eux même

- Les biologistes non  expert de l'informatique est une challenge vu le nombre important de notions a apprendre utilisation d'un ordi, gestion de projet, statistique. Il faut décomposer ces notions en 5 quadrimestre continue

- Le logiciel reste vu comme pointu et diffficile d'utilisation (SUS).

- l'evaluation continue et l'analyse de projet via des grilles critérié semble une approche intéressante pour juger de la capacité des étudiant à bosser.

- la catégorisation des étudiants démontre une grande diversité de profils. Premier élément vers une pédagogie différencié  vers 

# References
