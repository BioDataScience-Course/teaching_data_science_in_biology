% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Teaching Data Science to Students in Biology using R, RStudio and Learnr: Analysis of Three years Data},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1 \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces\fi
  % set entry spacing
  \ifnum #2 > 0
  \setlength{\parskip}{#2\baselineskip}
  \fi
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\title{Teaching Data Science to Students in Biology using R, RStudio and
Learnr: Analysis of Three years Data}
\author{}
\date{\vspace{-2.5em}}

\begin{document}
\maketitle

\hypertarget{abstract}{%
\section{Abstract}\label{abstract}}

\textbf{This is the original abstract that should be reworked according
to final content of the manuscript.}

The courses in biostatistics in biology at the University of Mons,
Belgium, were completely refactored in 2018 into data science courses
(see \url{http://bds.sciviews.org}). The content is expanded beyond
statistics to include computing tools, version management, reproducible
analyses, critical thinking and open data. Flipped classroom approach is
used. Students learn with the online material and they apply the
concepts on individual and group projects using a preconfigured virtual
machine with R and RStudio. Activities (H5P, learnr or Shiny
applications) are recorded in a MongoDB database (300,000+ events for
180+ students and 2,000+ GitHub repositories at
\url{https://github.com/BioDataScience-Course}). The analysis of these
data reveals several trends. (1) There is a relatively long lag period
required for the students to get used to the computing environment, the
teaching method and the data science in general. (2) Implication is very
high, with more than 85\% of the students that complete all the
activities and got good to excellent assessment. (3) There is a gap
between students' own perception of their skills achievements and their
assessment results: they tend to underestimate their progress. (4)
During COVID-19 pandemic lockdown, the intensity of the activities
largely decreased during two weeks before returning to previous level,
but for 3/4 of the students only. The remaining fraction never caught
up. We hypothesize that the technical requirements or the lack of
motivation during the lockdown were detrimental to roughly one student
over ten, despite all the efforts the University deployed to reduce the
social fracture.

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

In a context where there is an exponentially growing mass of data
{[}ref\ldots{]}, a reproducibility crisis in Science (Baker 2016), and a
progressive adoption of Open Science practices (Banks et al. 2019),
statistics were broaden to a larger discipline called Data Science. For
the Data Science association, ``the Data Science means the scientific
study of the creation, validation and transformation of data to create
meaning'' (\url{http://www.datascienceassn.org/code-of-conduct.html}).
These changes also led to the emergence of data science programs in
universities and higher schools (Donoho 2017; Çetinkaya-Rundel and
Ellison 2021). One example is the Harvard Data Science initiative
(\url{https://datascience.harvard.edu/about}) initiated in 2017. With a
broader approach, comes also a broaden public. The data science courses
are not just limited to computer scientists, mathematicians or
statisticians, but also welcome students in humanities, social sciences,
and natural sciences (for instance, the data science training at Duke
University (Çetinkaya-Rundel and Ellison 2021)). Main focus of such
courses is for students to develop the ability to deal with ``real''
datasets in all their complexities and to realize reproducible analyses
to interpret these data in the light of knowledge in their field of
expertise.

The data transformation part of the job is a challenge for students with
a poor or no background at all in computing. Students that are not used
to deal with computer languages enter in a foreign world and have to
deal with many exotic concepts, techniques and tools. This is the same
for the analysis of these data when students have no background in
mathematics or statistics. It generates anxiety (see for instance
(Onwuegbuzie and Wilson 2003), for students in biology). The course must
be organized in a way that such students progress by little steps in
order to avoid exposition to much intimidating concepts and tools at
once. Hence, a student in computing science already masters one or more
computing languages, is acquainted with version control systems, with
databases and with the way data are represented in a computer. A student
in mathematics or statistics is familiar with various concept that
underpin the techniques to analyse the data. On the other hand, students
in biology, medicine, psychology, social sciences, economics, \ldots{}
have very different \emph{a priori} knowledges. Version control systems
like git, and their internet hosting counterparts like GitHub, Gitlab or
Bitbucket also make part of the tools that data science course teach and
use (Fiksel et al. 2019; Hsing and Gennarelli 2019). Presentation of the
results and the use of documents formats that dissociate content from
presentation, namely LaTeX, Jupyter Notebook, or R Markdown also
contribute to the large number of potentially new tools students have to
learn (Baumer et al. 2014).

Suitable computer hardware and software environments are required in the
practical sessions of the courses. Different approaches range from
inline software (RStudio Cloud {[}ref{]}, Chromebook data science
{[}ref{]}) to local installation on the Student's computers. The former
requires an infrastructure to run the software on a server, nad that
software is only accessible to the students during the course. The later
raises problems of license for proprietary software, but also
installation and configuration issues. An intermediary solution uses
preconfigured virtual machines, or containers (e.g., Docker)
(Çetinkaya-Rundel and Rundel 2018). Such a solution is the most flexible
because it can be deployed almost anywhere (in the computer lab, at
home, using a laptop, \ldots). To fix theoretical concepts through
applied exercises is a key aspect of learning data science (Larwin and
Larwin 2011). Correct choice of software is critical and exposing
students early with the tools they are most susceptible to use later in
their work is desirable. This was highlighted by (Auker and Barthelmess
2020) for instance, for the analysis of ecological data.

These data science courses pose several challenges to pedagogy because
various, numerous and unfamiliar concepts must be acquired by a
population of potentially very diverse students. Learning objectives
span a large range of cognitive abilities (Krathwohl 2002). {[}We need
to develop here things like flipped classroom, continuous evaluation,
pedagogy by projects, and inclusive pedagogy{]}. The flipped classroom
approach allows students to be active in their learning, which has the
benefit of improving student outcomes (Freeman et al. 2014).

{[}Partie pédagogie à détailler un peu, probablement sur 2 ou 3
paragraphes{]}

Recently, data science is also used to analyze the effect of different
pedagogical practices on the outcome of these courses {[}Estrellado et
al. (2020); second ref to add{]}. A vast amount of data can be collected
on students activities, and the analysis of these data allows to compare
the impact of different pedagogical approaches, or to quantify and
document the impact of changes in the courses.

At the University of Mons in Belgium, we have started to rework our
biostatistics courses in the biology curriculum in 2018. A series of
Data Science courses were introduced, both for our undergraduate and
graduate students. These courses are inspired from precursor initiatives
cited here above. The goal of these courses is to form biological data
scientists capable to extract meaningful information from raw biological
data, and to do so in a reproducible way, with correct application of
statistical tools and an adequate critical mindset. A preconfigured
VirtualBox virtual machine with R, RStudio, Rmarkdown, git, and a series
of R packages preinstalled is used (url sciviews box?) as a very
flexible way to deploy the same software environment both on the
university computers and on student's own laptops.

As our course were completely reworked, we also decided to use flipped
classroom and progressive adoption of suitable pedagogical practices
with a cyclical approach that consists in stating goals, building
pedagogical material with a large emphasis on numerical tools and
collection of student's activities, and finally, analysis of the data
collected. Conclusions of these analyses initiate another cycle the
following academic year with refined goals and pedagogical materials and
techniques. Here, we present the main results spanning on three
successive academic years from 2018 to 2021, including two particular
periods where distance learning was forced due to COVID pandemic
lockdown.

{[}TODO: present here the 3-4 research questions that will be elaborated
in the manuscript.{]}

\hypertarget{methods}{%
\section{Methods}\label{methods}}

The course materials are available online
(\url{https://wp.sciviews.org}) and are centralized in a Wordpress site.
Students have to login with their GitHub account and their academic data
are collected from the UMONS Moodle server. The courses are break down
into modules that amount roughly to 15h of work each in total. There are
two sessions of 2h and 4h in the classroom (outside of lockdown periods,
of course). Main activities in the class are actual data analysis
(projects), answering student questions, and very sort lectures of 1/4h
on selected topics. Students propose and vote for the topics to be
covered during these short lectures. Finally, we encourage students to
help each other and to explain what they understand to their colleagues.
Indeed, students' questions may be redirected to other students that
have already mastered the topic by the educators. On the other hand,
teachers rarely answer questions directly. When it is possible, they
rather propose new tracks or ideas to investigate in order to find the
solution by oneself. Students that have finished the work before the
others are encouraged to help their colleagues too.

Regarding the timing, one module it taught every second week so that
students have enough time to prepare the material at home and then, to
finalize their projects before the next module. Since a term is 14
weeks, we do not teach more than six modules in a course unit to avoid
compacting them in time at a faster pace than one module every second
week.

All student activities in H5P exercises for their auto-evaluation, and
in learnr tutorials to transition smoothly from the theory to the
practice are recorded in the MongoDB database. The learnitdown R package
(\url{https://www.sciviews.org/learnitdown/}) provides the functions
required to manage user login, user identification and activity tracking
in the interactive material.

Projects with the data, the analyses and te reports are hosted in GitHub
repositories. These repositories are cloned and edited locally with
RStudio, either on a PC in the computer lab, or directly on the
student's laptop. We encourage our students to install the virtual
machine on their own computer so that they can use it for other courses
too. Assignment and creation of the GitHub repositories for each
student, or group of students is orchestrated with GitHub Classroom. All
repositories are ultimately cloned in a centralized area on our servers
and data about commits (git logs) are collected using git version
{[}XXX{]} and R version 4.0.5. To give an idea of the amount of data
recorded, in 2020-2021 we have a little bit more than 2,500 events per
student.

In distance learning, support to the students was done via email and
Discord. At the end, all messages that were exchanged are collected
together into text files. These files are scraped using R code to create
a table with key information (basically, who, when, and what) for each
message. Surveys are periodically conducted during lessons by means of
Wooclap questionnaires (see, for instance, the Nasa-LTX questionnaire
analysis in the results section). Wooclap allows to export data into
Excel files. These data are then converted into a table in our database.

Information about users, courses, lessons and projects, as well as
grading items (on average, more that 130 grading items were established
for each student in 2020-2021) are anonymized: name, email and all the
personal information are replaced by random identifiers. The different
tables are ultimately exported into CSV files and made public. These
data are available at {[}\ldots{} Zenodo?{]}. Data collection,
treatment, and use respect European GDPR (General Data Protection
Regulation) since each student had to agree explicitly with the way data
are collected and used (including for research purpose) before the
course begins. They can visualize their own data through personalized
reports at anytime.

The course material is organized in a way that favour autonomy and
auto-evaluation (direct feedback in the exercises, hints and retry
button in case of wrong answer). Activities span into a sequence of
exercises of increasing difficulty, ranging from Level 1 to level 4.
Table 1 summarizes main characteristics of the exercises according to
the level.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.06}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.78}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.16}}@{}}
\caption{for levels of increasing difficulties in the
exercises.}\tabularnewline
\toprule
Level & Description & Type \\
\midrule
\endfirsthead
\toprule
Level & Description & Type \\
\midrule
\endhead
L1 & Short exercise directly integrated in the course and with direct
feedback for auto-evaluation & h5p \\
L2 & Guided exercise with contextual feedback within a short tutorial &
learnr \\
L3 & Individual and guided data analysis & individual project \\
L4 & More complex and free data analysis and reporting (group of 2 or 4
students) & group project \\
\bottomrule
\end{longtable}

{[}one or two paragraphs to describe statistical methods used
here\ldots{]}

The NASA-LTX questionnaire is composed of six questions on a Likert
scale to quantify the perceived workload to complete a task (Hart and
Staveland 1988). The questions concern mental load, physical load, time
pressure, expected success, effort required, and frustration experienced
during the accomplishment of the task. The average value for the six
questions constitutes a Raw Task Load indeX (RTLX) (Byers, Bittner, and
Hill 1989) that we use to quantify how students perceive the workload of
a given task.

\hypertarget{results}{%
\section{Results}\label{results}}

Liste des idées développées dans cette section :

\begin{itemize}
\tightlist
\item
  exam versus project 2018 et 2019 =\textgreater{} elimination de
  l'examen
\item
  profiles analyse SOM =\textgreater{} sous-groupes + analyse des
  groupes y compris comparaison avec les grades
\item
  temporel présentiel -\textgreater{} distanciel
\item
  learnrs (+ perception) -\textgreater{} apprentissage sur le très long
  terme (\textgreater{} 1 ou deux quadris)
\end{itemize}

{[}Next paragraph to be translated and reworked{]}

La transition du cours classique vers une cours en classe inversée a
menée à l'intégration de nouveaux outils permettant de diversifier les
types d'exercice proposés aux étudiants (tab M\&M). Le tableau XX (il
semble avoir disparu dans l'édition du document???) indique la
répartition des exercices pour chaque cours. La collecte des données
pour chaque exercice permet de construire une note objective pour chaque
étudiant. La note des étudiant est construite sur l'évaluation des 5
niveaux d'exercices complémentaires allant des exercices les plus
simples (N1) aux exercices les plus complexes (N5). Une moyenne pondérée
pour chaque niveau d'exercice est employée pour obtenir une note finale
par cours.

Our in-service training includes 26 complementary modules over 3 years
and 3 consecutive courses from bab2 to MA1. The number of exercises per
type is shown in Table XXX. The goal and the difficulty levels of the
exercises are presented in table xxx. The completion of each exercise is
recorded in a database which allows an objective grade to be constructed
for each student.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Tab of number of users and number of exercices by type {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\CommentTok{\# users}
\NormalTok{users }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{filter}\NormalTok{(., institution }\SpecialCharTok{==} \StringTok{"UMONS"} \SpecialCharTok{\&}\NormalTok{ term }\SpecialCharTok{==} \StringTok{"Q1"} \SpecialCharTok{\&}\NormalTok{ state }\SpecialCharTok{==} \StringTok{"regular"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{group\_by}\NormalTok{(., course) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{summarise}\NormalTok{(., }\AttributeTok{user =} \FunctionTok{n}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{ungroup}\NormalTok{(.) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{filter}\NormalTok{(., course }\SpecialCharTok{!=} \StringTok{"D"}\NormalTok{)}\OtherTok{{-}\textgreater{}}\NormalTok{ us\_tab}

\CommentTok{\# learnr}
\NormalTok{learnr }\SpecialCharTok{\%\textgreater{}.\%} 
  \FunctionTok{filter}\NormalTok{(., }\SpecialCharTok{!}\NormalTok{app }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"A06Lb\_recombinaison"}\NormalTok{, }\StringTok{"A99La\_avis"}\NormalTok{, }\StringTok{"B00La\_rappel"}\NormalTok{, }\StringTok{"B99La\_avis"}\NormalTok{,}\StringTok{"C99La\_avis"}\NormalTok{) }\SpecialCharTok{\&} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(label)) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{mutate}\NormalTok{(., }\AttributeTok{course =} \FunctionTok{substr}\NormalTok{(app,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{),}
    \AttributeTok{app\_label =} \FunctionTok{paste0}\NormalTok{(app, label)) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{filter}\NormalTok{(., course }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{, }\StringTok{"C"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{group\_by}\NormalTok{(., course) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{summarise}\NormalTok{(., }\AttributeTok{app =} \FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(app)), }\AttributeTok{questions =} \FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(app\_label))) }\OtherTok{{-}\textgreater{}}\NormalTok{ learnr\_tab }

\CommentTok{\# projects}
\NormalTok{projects }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{filter}\NormalTok{(., type }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"ind. github"}\NormalTok{, }\StringTok{"group github"}\NormalTok{) }\SpecialCharTok{\&}\NormalTok{ course }\SpecialCharTok{!=} \StringTok{"D"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{group\_by}\NormalTok{(., course, type) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{count}\NormalTok{(.) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{pivot\_wider}\NormalTok{(., }\AttributeTok{names\_from =} \StringTok{"type"}\NormalTok{, }\AttributeTok{values\_from =} \StringTok{"n"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{ungroup}\NormalTok{(.) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{select}\NormalTok{(., course, }\StringTok{\textasciigrave{}}\AttributeTok{ind. github}\StringTok{\textasciigrave{}}\NormalTok{, }\StringTok{\textasciigrave{}}\AttributeTok{group github}\StringTok{\textasciigrave{}}\NormalTok{)}\OtherTok{{-}\textgreater{}}\NormalTok{ projects\_tab}
    
\CommentTok{\# tab number of exercices by type {-}{-}{-}}
\NormalTok{assessments }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{filter}\NormalTok{(., type }\SpecialCharTok{==} \StringTok{"h5p"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{mutate}\NormalTok{(., }
    \AttributeTok{app\_type =} \FunctionTok{paste0}\NormalTok{(app, }\StringTok{"\_"}\NormalTok{ ,}\StringTok{\textquotesingle{}type\textquotesingle{}}\NormalTok{),}
    \AttributeTok{course =} \FunctionTok{substr}\NormalTok{(app, }\AttributeTok{start =} \DecValTok{1}\NormalTok{, }\AttributeTok{stop =} \DecValTok{1}\NormalTok{),}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{group\_by}\NormalTok{(., course) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{summarise}\NormalTok{(., }\AttributeTok{h5p =} \FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(app\_type))) }\OtherTok{{-}\textgreater{}}\NormalTok{ h5P\_tab}

\NormalTok{us\_tab }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{mutate}\NormalTok{(., }\AttributeTok{module =} \FunctionTok{c}\NormalTok{(}\DecValTok{12}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{6}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{left\_join}\NormalTok{(., h5P\_tab) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{left\_join}\NormalTok{(., }\FunctionTok{mutate}\NormalTok{(learnr\_tab, }\AttributeTok{learnr =} \FunctionTok{paste0}\NormalTok{(app, }\StringTok{" ("}\NormalTok{, questions, }\StringTok{")"}\NormalTok{), }\AttributeTok{.keep =} \StringTok{"unused"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{left\_join}\NormalTok{(., projects\_tab) }\SpecialCharTok{\%\textgreater{}.\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(., }\AttributeTok{caption =} \StringTok{"Number of users, modules, exercises with h5p, learnr tutorial,individual project and group project by course. The number of quesion by learnr tutorial are in the parentheses."}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrlrr@{}}
\caption{Number of users, modules, exercises with h5p, learnr
tutorial,individual project and group project by course. The number of
quesion by learnr tutorial are in the parentheses.}\tabularnewline
\toprule
course & user & module & h5p & learnr & ind. github & group github \\
\midrule
\endfirsthead
\toprule
course & user & module & h5p & learnr & ind. github & group github \\
\midrule
\endhead
A & 42 & 12 & 59 & 24 (211) & 10 & 4 \\
B & 40 & 8 & 29 & 11 (108) & 12 & 2 \\
C & 25 & 6 & 19 & 7 (37) & 7 & 1 \\
\bottomrule
\end{longtable}

\hypertarget{exams-versus-project}{%
\subsection{Exams versus project}\label{exams-versus-project}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{assessments18 }\SpecialCharTok{\%\textgreater{}.\%}
  \CommentTok{\#select(., {-}coral\_growth, result = biometry) \%\textgreater{}.\%}
  \FunctionTok{mutate}\NormalTok{(., }\AttributeTok{result =}\NormalTok{ (biometry}\SpecialCharTok{+}\NormalTok{coral\_growth)}\SpecialCharTok{/}\DecValTok{2}\NormalTok{, }\AttributeTok{acad\_year =} \StringTok{"2018{-}2019"}\NormalTok{) }\OtherTok{{-}\textgreater{}}\NormalTok{ assess\_result18}
  
\NormalTok{q1\_18\_regular }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(}\FunctionTok{rename}\NormalTok{(assess\_result18, }\AttributeTok{icourse =}\NormalTok{ course), courses18) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{filter}\NormalTok{(., user }\SpecialCharTok{\%in\%}\NormalTok{ users18}\SpecialCharTok{$}\NormalTok{user[users18}\SpecialCharTok{$}\NormalTok{institution }\SpecialCharTok{==} \StringTok{"UMONS"} \SpecialCharTok{\&}\NormalTok{ users18}\SpecialCharTok{$}\NormalTok{term }\SpecialCharTok{==} \StringTok{"Q1"} \SpecialCharTok{\&}\NormalTok{ users18}\SpecialCharTok{$}\NormalTok{state }\SpecialCharTok{==} \StringTok{"regular"}\NormalTok{])}

\NormalTok{assessments19 }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{group\_by}\NormalTok{(., course, evaluation, github\_project, project, user) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{summarise}\NormalTok{(., }\AttributeTok{result =} \FunctionTok{round}\NormalTok{(}\FunctionTok{sum}\NormalTok{(score}\SpecialCharTok{*}\NormalTok{weight),}\DecValTok{4}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{filter}\NormalTok{(., evaluation }\SpecialCharTok{==} \StringTok{"Q1"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{left\_join}\NormalTok{(exam19, .) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{replace\_na}\NormalTok{(., }\FunctionTok{list}\NormalTok{(}\AttributeTok{result =} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{mutate}\NormalTok{(., }\AttributeTok{acad\_year =} \StringTok{"2019{-}2020"}\NormalTok{)}\OtherTok{{-}\textgreater{}}\NormalTok{ assess\_result19}

\NormalTok{q1\_19\_regular }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(}\FunctionTok{rename}\NormalTok{(assess\_result19, }\AttributeTok{icourse =}\NormalTok{ course), courses19) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{filter}\NormalTok{(., user }\SpecialCharTok{\%in\%}\NormalTok{ users19}\SpecialCharTok{$}\NormalTok{user[users19}\SpecialCharTok{$}\NormalTok{institution }\SpecialCharTok{==} \StringTok{"UMONS"} \SpecialCharTok{\&}\NormalTok{ users19}\SpecialCharTok{$}\NormalTok{term }\SpecialCharTok{==} \StringTok{"Q1"} \SpecialCharTok{\&}\NormalTok{ users19}\SpecialCharTok{$}\NormalTok{state }\SpecialCharTok{==} \StringTok{"regular"}\NormalTok{])}

\NormalTok{q1 }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(}
  \FunctionTok{select}\NormalTok{(q1\_18\_regular, user, acad\_year, course, result, exam),}
  \FunctionTok{select}\NormalTok{(q1\_19\_regular, user, acad\_year, course, result, exam)}
\NormalTok{  )}
\CommentTok{\#table(q1$link) /nrow(q1)}
\end{Highlighting}
\end{Shaded}

Until the first four months of the 2019-2020 academic year, students'
grades were based on the completion of a project and a more conventional
examination during the examination period. The projects are assessed
using a grading grid since the 2019-2020 academic year.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{q1 }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{mutate}\NormalTok{(., }\AttributeTok{course\_year =} \FunctionTok{paste0}\NormalTok{(course, }\StringTok{" ("}\NormalTok{,acad\_year,}\StringTok{")"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{chart}\NormalTok{(., exam }\SpecialCharTok{\textasciitilde{}}\NormalTok{ result }\SpecialCharTok{|}\NormalTok{ course\_year) }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =} \DecValTok{5}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \DecValTok{5}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_jitter}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{1}\NormalTok{, }\AttributeTok{width =} \FloatTok{0.05}\NormalTok{, }\AttributeTok{height =} \FloatTok{0.05}\NormalTok{, }\AttributeTok{show.legend =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylim}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{10}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{xlim}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{10}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y =} \StringTok{"Exam grade"}\NormalTok{, }\AttributeTok{x =} \StringTok{"Project grade"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{teaching_data_science_files/figure-latex/unnamed-chunk-3-1.pdf}

The comparison of the marks obtained between the project and the exam
mark shows a strong disparity between these two types of evaluation.

The 2018-2019 year is the first year of transition to data science
courses. Only one student failed the project, while almost one third of
the students failed their exams. The level of requirements is being
raised for the 2019-2020 academic year. The new expectations and the
introduction of evaluation grids to assess projects show a greater
disparity in students' grades.

Despite an examination that includes theoretical and practical
questions, this type of assessment does not assess a student's ability
to correctly process and analyse biological data.

Following these results and the monitoring of more precise exercises,
the examination is definitively abandoned for the 2020-2021 academic
year to be replaced by a continuous assessment.

\hypertarget{students-profiles}{%
\subsection{Students' profiles}\label{students-profiles}}

{[}TODO : Add SOM analyses, This analysis is stand by as we validate the
metrics{]}

Les groupes réalisés créent des profils d'apprenants ayant des
stratégies très différentes. Puisque certains profils sont plutôt
associées aux notes plus faible, ces groupes devront faire l'objet d'une
attention particulière et peut-être aussi d'une adaptation du matéirel
ou de l'approche pédagogique vers un apprentissage plus inclusif.

\hypertarget{transition-between-face-to-face-and-distance-learning}{%
\subsection{Transition between face-to-face and distance
learning}\label{transition-between-face-to-face-and-distance-learning}}

Due to Covid-19 lockdown periods, distance learning had to be adopted
abruptly. We analyze the activity and support data collected during
academic years 2019-2020 and 2020-2021 to assess the impact of this
transition on the progression of the students and

{[}TODO : add analyse on the commit or h5P/learnr exercises to follow
the student{]}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{log19 }\SpecialCharTok{\%\textgreater{}.\%} 
  \FunctionTok{distinct}\NormalTok{(., commit, }\AttributeTok{.keep\_all =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{filter}\NormalTok{(., }\FunctionTok{is.na}\NormalTok{(from)) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{mutate}\NormalTok{(., }\AttributeTok{date\_round =}\NormalTok{ lubridate}\SpecialCharTok{::}\FunctionTok{round\_date}\NormalTok{(date, }\StringTok{"day"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{group\_by}\NormalTok{(., date\_round) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{count}\NormalTok{(.) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{ungroup}\NormalTok{(.) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{mutate}\NormalTok{(., }\AttributeTok{cumul\_commit =} \FunctionTok{cumsum}\NormalTok{(n)) }\OtherTok{{-}\textgreater{}}\NormalTok{ log19\_red}


\NormalTok{log19\_red }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{filter}\NormalTok{(., date\_round }\SpecialCharTok{\textgreater{}}\NormalTok{ lubridate}\SpecialCharTok{::}\FunctionTok{ymd}\NormalTok{(}\StringTok{"2020{-}02{-}01"}\NormalTok{) }\SpecialCharTok{\&}\NormalTok{ date\_round }\SpecialCharTok{\textless{}}\NormalTok{ lubridate}\SpecialCharTok{::}\FunctionTok{ymd}\NormalTok{(}\StringTok{"2020{-}05{-}22"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{chart}\NormalTok{(., cumul\_commit }\SpecialCharTok{\textasciitilde{}}\NormalTok{ date\_round) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =} \FunctionTok{as.POSIXct}\NormalTok{(}\StringTok{"2020{-}03{-}15"}\NormalTok{), }\AttributeTok{color =} \StringTok{"red"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Date"}\NormalTok{, }\AttributeTok{y =} \StringTok{"cumulative sum of commits"}\NormalTok{) }\OtherTok{{-}\textgreater{}}\NormalTok{ p1}

\NormalTok{log }\SpecialCharTok{\%\textgreater{}.\%} 
  \FunctionTok{distinct}\NormalTok{(., commit, }\AttributeTok{.keep\_all =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{filter}\NormalTok{(., }\FunctionTok{is.na}\NormalTok{(from)) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{mutate}\NormalTok{(., }\AttributeTok{date\_round =}\NormalTok{ lubridate}\SpecialCharTok{::}\FunctionTok{round\_date}\NormalTok{(date, }\StringTok{"day"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{group\_by}\NormalTok{(., date\_round) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{count}\NormalTok{(.) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{ungroup}\NormalTok{(.) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{mutate}\NormalTok{(., }\AttributeTok{cumul\_commit =} \FunctionTok{cumsum}\NormalTok{(n)) }\OtherTok{{-}\textgreater{}}\NormalTok{ log\_red}


\NormalTok{log\_red }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{filter}\NormalTok{(., date\_round }\SpecialCharTok{\textless{}}\NormalTok{ lubridate}\SpecialCharTok{::}\FunctionTok{ymd}\NormalTok{(}\StringTok{"2020{-}11{-}15"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{chart}\NormalTok{(., cumul\_commit }\SpecialCharTok{\textasciitilde{}}\NormalTok{ date\_round) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =} \FunctionTok{as.POSIXct}\NormalTok{(}\StringTok{"2020{-}10{-}21"}\NormalTok{), }\AttributeTok{color =} \StringTok{"red"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Date"}\NormalTok{, }\AttributeTok{y =} \StringTok{"cumulative sum of commits"}\NormalTok{) }\OtherTok{{-}\textgreater{}}\NormalTok{ p2}

\FunctionTok{combine\_charts}\NormalTok{(}\FunctionTok{list}\NormalTok{(p1, p2))}
\end{Highlighting}
\end{Shaded}

\includegraphics{teaching_data_science_files/figure-latex/unnamed-chunk-4-1.pdf}

During the first lockdown, support rapidly switched to the proposed
channels, by email and via Discord. However, despite a sustained
exchange of message, progression of the students in the course material
almost stopped for two weeks before taking over (graph A) \ldots. During
the second lockdown \ldots{} {[}make plots and analyse this\ldots{]}

\hypertarget{learnr-tutorials-perceived-cognitive-workload}{%
\subsection{Learnr tutorials perceived cognitive
workload}\label{learnr-tutorials-perceived-cognitive-workload}}

The learnr tutorials play an essential role in the progressive
acquisition of competences because they are at the transition between
the theory (online book chapters) and the practice (projects where
student analyze real biological data by themselves). Our goal is to
prepare our students optimally for the practice of data science. In the
other hand, we don't want to exhaust their mental energy in these
tutorials before they start their projects. The efficiency of these
tutorials is qualitatively determined by observing the behaviour of the
students when they start their practical work. A few tutorials were
elaborated during the academic year 2018-2019, and positive feedback on
their utility (both by direct observation of the pupils, and by their
remarks) led us to systematize them into what we now call level 2
activities (see Table XX) in the form of learnr documents in 2019-2020.
The tutorials were further refined in 2020-2021: we added contextual
hints thanks to the gradethis R package. When students submit their
answer to the exercises, the R code is analyzed and the results are
compared with the solution. In case of differences, heuristics are used
to provide contextual hints. Students can then refine their solution and
resubmit it. This appears very efficient in self-teaching and
self-evaluation of their competences before switching to the practice.
However, the cognitive load required to perform these exercises has, as
far as we know, not been studied yet. We used a NASA LTX questionnaire
to assess it across all three courses {[}indicate here the level of
participation of the students for each course{]}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{c}\NormalTok{(}\StringTok{"A99Wa\_perception"}\NormalTok{, }\StringTok{"B99Wa\_perception"}\NormalTok{, }\StringTok{"C99Wb\_perception:perception"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  purrr}\SpecialCharTok{::}\FunctionTok{map\_dfr}\NormalTok{(learnr\_feeling, }\AttributeTok{df =}\NormalTok{ wo, }\AttributeTok{label =} \StringTok{"Q4"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{mutate}\NormalTok{(., }\AttributeTok{course =} \FunctionTok{substr}\NormalTok{(app, }\AttributeTok{start =} \DecValTok{1}\NormalTok{, }\AttributeTok{stop =} \DecValTok{1}\NormalTok{)) }\OtherTok{{-}\textgreater{}}\NormalTok{ learnr\_workload}

\NormalTok{learnr\_workload }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{pivot\_longer}\NormalTok{(.,}\AttributeTok{cols =} \FunctionTok{c}\NormalTok{(mental, physical, time\_pressure, performance, effort, frustration),}
  \AttributeTok{names\_to =} \StringTok{"category"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"grade"}\NormalTok{)  }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{left\_join}\NormalTok{(., dplyr}\SpecialCharTok{::}\FunctionTok{distinct}\NormalTok{(courses, course,name), }\AttributeTok{by =} \StringTok{"course"}\NormalTok{)}\OtherTok{{-}\textgreater{}}\NormalTok{ workload}

\NormalTok{workload }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{group\_by}\NormalTok{(., user, app, course) }\SpecialCharTok{\%\textgreater{}.\%}
  \CommentTok{\#filter(., user != "ECAYEO033") \%\textgreater{}.\%}
  \FunctionTok{summarise}\NormalTok{(., }\AttributeTok{rtlx =} \DecValTok{10}\SpecialCharTok{*}\FunctionTok{mean}\NormalTok{(grade)) }\OtherTok{{-}\textgreater{}}\NormalTok{ workload\_rtlx}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{222}\NormalTok{)}
\FunctionTok{chart}\NormalTok{(workload\_rtlx, rtlx }\SpecialCharTok{\textasciitilde{}}\NormalTok{ course) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{(}\AttributeTok{fill =} \StringTok{"\#00BFC4"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_jitter}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{width =} \FloatTok{0.1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y =} \StringTok{"RTLX"}\NormalTok{, }\AttributeTok{x =} \StringTok{"Course"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{stat\_summary}\NormalTok{(}\AttributeTok{fun.y=}\StringTok{"mean"}\NormalTok{, }\AttributeTok{color =} \StringTok{"red"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{stat\_summary}\NormalTok{(}\AttributeTok{fun.data =}\NormalTok{ n\_fun, }\AttributeTok{geom =} \StringTok{"text"}\NormalTok{, }\AttributeTok{hjust =} \FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{( }\AttributeTok{y =} \StringTok{"Raw Task Load indeX (2020{-}2021)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{teaching_data_science_files/figure-latex/unnamed-chunk-5-1.pdf}

The difficulty of the course, and thus, of the exercises in the
tutorials increase from one course to the other. However, we do not
observe an increase in the RTLX index. On the contrary, it is
significantly lower for course C than for course A (Tukey HSD, p-value =
0.023). The cognitive load perceived by the students diminishes. This
may be a consequence of a more fluent R coding and the better mastering
of all the software tools the students have to use.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{workload\_rtlx }\SpecialCharTok{\%\textgreater{}.\%}
  \FunctionTok{mutate}\NormalTok{(., }\AttributeTok{course =} \FunctionTok{as.factor}\NormalTok{(course)) }\OtherTok{{-}\textgreater{}}\NormalTok{ workload\_rtlx}

\CommentTok{\#kruskal.test(data = workload\_rtlx, rtlx \textasciitilde{} course)}
\CommentTok{\#summary(kw\_comp. \textless{}{-} nparcomp::nparcomp(data = workload\_rtlx, rtlx \textasciitilde{} course))}

\NormalTok{anova. }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(}\AttributeTok{data =}\NormalTok{ workload\_rtlx, rtlx }\SpecialCharTok{\textasciitilde{}}\NormalTok{ course)}
\FunctionTok{anova}\NormalTok{(anova.)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Variance Table
## 
## Response: rtlx
##           Df  Sum Sq Mean Sq F value  Pr(>F)  
## course     2   926.9  463.47  3.5883 0.03134 *
## Residuals 98 12658.0  129.16                  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#bartlett.test(data = workload\_rtlx, rtlx \textasciitilde{} course)}
\CommentTok{\#plot(anova., which = 2)}

\FunctionTok{summary}\NormalTok{(anovaComp. }\OtherTok{\textless{}{-}} \FunctionTok{confint}\NormalTok{(multcomp}\SpecialCharTok{::}\FunctionTok{glht}\NormalTok{(anova.,}
  \AttributeTok{linfct =}\NormalTok{ multcomp}\SpecialCharTok{::}\FunctionTok{mcp}\NormalTok{(}\AttributeTok{course =} \StringTok{"Tukey"}\NormalTok{))))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: lm(formula = rtlx ~ course, data = workload_rtlx)
## 
## Linear Hypotheses:
##            Estimate Std. Error t value Pr(>|t|)  
## A - B == 0    2.356      2.526   0.933   0.6183  
## C - B == 0   -6.058      3.296  -1.838   0.1607  
## C - A == 0   -8.414      3.141  -2.679   0.0229 *
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## (Adjusted p values reported -- single-step method)
\end{verbatim}

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

{[}juste quelques idées\ldots{} à développer et à traduire en anglais
bien sûr.{]}

\begin{itemize}
\item
  L'examen en fin de période, même s'il reprend des questions liées à de
  la pratique et de l'utilisation d'outils, ne mène pas à une évaluation
  formtement corrélée avec l'activité qui nous intéresse le plus, à
  savoir, la capacité de l'étudiant à analyser des données billogiques
  réelles. Cette capacité est parfaitement évaluée dans les projets de
  niveau 1, et surtout de niveau 2 qui correspondent très précisément à
  une telle activité. Par conséquent, l'évaluation ne se fait plus via
  un examen final, mais uniquement via les prestations des étudiants
  dans les projets, ainsi que (pour une part relativement faible de 15\%
  de la note finale), leur progression dans l'apprentissage de la
  matière via la réalisation des exercises de niveau 1 et des tutoriels
  de niveau 2, ceci afin de les encourager à réaliser complètement tous
  les exercises et à les faire dans l'ordre croissant de difficulté.
\item
  Même au sein d'une cohortez d'étudiants ayant un parcours académique
  similaire, nous notons de très grosses différences de stratégie dans
  les activités d'apprentissage. Si plusieurs stratégies différentes
  sont associées à une acquisirtion bonne à erxcellente des compétences
  telle qu'attestée par les notes obtenues, plusieurs profils sont
  systématiquement associés à des performances faibles. Les profils
  ainsi établis via cartes auto-adaptatives permettront à l'avenir de
  détecter plus tôt les étudiants à suivre plus particulièrement et à
  réfléchir à des approiches alternatives pour eux afin de les aider
  (pédagogie inclusive).
\item
  Les études portant sur le changements d'attitudes au sein de semestre
  ne montre pas différence significative. La comparaison entre les 3
  cours met en avant qu'il faut plusieurs cours en continu afin
  d'observer une changement de la charge cognitive des étudiants.
\item
  Apprentissage en continu sur 3 années successives (cohérence entre le
  programme et l'approche pédagogique), les résultats sont meilleurs
  vers la 3ieme années.
\item
  Pendant les périodes de confinements, le passage brutal à des cours en
  présentiel vers des cours en distaznciel nécesite une période
  d'adaptation que nous avons quantifié dans notre cas à environ 2
  semaine. Il s'agit ici du temps d'adaptation des étudiants, sachant
  que du côté des enseignants, nous avons réagit immédiatement (et même
  anticipé) en mettant en place très rapidement les canaux de
  communication alternatifs via le mail et Discord.
\item
  Les tutoriels learnrs jouent un rôle charnière entre la théorie et la
  pratique. Ils offrent la possibilité de préparer les étudiants de
  manière optimale à l'analyse de données en pratique. Nous avans
  quantifié la charge cognitive perçue. Si la valeur absolue de l'index
  RTX n'est pas informative, la comparaison d'index obtenus dans des
  situations différentes permet de déterminer laquelle de ces situations
  est la mieux perçue. La compraison des trois cours successifs montre
  une diminution de cette charge cognitive perçue dans le dernier cours
  qui est pourtant le plus avancé et le plus difficile. A l'avenir, nous
  pourrons utiliser ces points de référence pour encore améliorer ces
  tutoriels de ce pôint de vue.
\end{itemize}

\hypertarget{conclusions}{%
\section{Conclusions}\label{conclusions}}

\begin{itemize}
\item
  Exam classique évalue mal la capacité d'evaluer des données
  biologiques par eux même
\item
  Les biologistes non expert de l'informatique est une challenge vu le
  nombre important de notions a apprendre utilisation d'un ordi, gestion
  de projet, statistique. Il faut décomposer ces notions en petites
  étapes successives si nous ne voulons pas les perdre rapidement. Notre
  approche en 3 cours étalés sur 5 quadrimestres successifs et étalés
  sur 3 années semblent correspondre à un bon timing pour ce type
  d'étudiant qui, au départ, n'a aucune notion de statistique, et très
  peu de connaissance des outils des logiciels couramment utilisées par
  le scientifique des données.
\item
  Néanmoins, malgré leur habituation progressive, ces logiciels restent
  vus comme pointu et diffficile d'utilisation (SUS) {[}à voir si on met
  cela dans l'article: on a déjà beaucoup ! =\textgreater{} réserver
  cela pour un autre article l'annéde prochaine peut-être ?{]}.
\item
  l'evaluation continue et l'analyse de projet via des grilles critérié
  semble une approche intéressante pour juger de la capacité des
  étudiant à bosser {[}on a pas développé cela au final, il me
  semble{]}.
\item
  la catégorisation des étudiants en différents profils d'apprenants
  ayant adopté des stratégies très contrastées démontre une grande
  diversité des apprenants, même à l'intérieur d'un groupe a priori
  homogène (n,ous ne nous trouvons pas ici dans une grande classe qui
  regrouperait des étudiants d'horizons très différents comme les cours
  d'introduction à la science des données tels que pratiques dans
  certaines grandes universités américaines). Ceci est un premier pas
  vers une pédagogie différencié et plus inclusive qui s'avèrent être
  des éléments importants ici.
\end{itemize}

\hypertarget{references}{%
\section*{References}\label{references}}
\addcontentsline{toc}{section}{References}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\hypertarget{ref-Auker2020}{}%
Auker, Linda A., and Erika L. Barthelmess. 2020. {``{Teaching R in the
undergraduate ecology classroom: approaches, lessons learned, and
recommendations}.''} \emph{Ecosphere} 11 (4): e03060.
https://doi.org/\url{https://doi.org/10.1002/ecs2.3060}.

\leavevmode\hypertarget{ref-Baker2016}{}%
Baker, Monya. 2016. {``1,500 Scientists Lift the Lid on
Reproducibility.''} \emph{Nature} 533 (7604): 452--54.
\url{https://doi.org/10.1038/533452a}.

\leavevmode\hypertarget{ref-Banks2019}{}%
Banks, George C., James G. Field, Frederick L. Oswald, Ernest H.
O'Boyle, Ronald S. Landis, Deborah E. Rupp, and Steven G. Rogelberg.
2019. {``{Answers to 18 Questions About Open Science Practices}.''}
\emph{Journal of Business and Psychology} 34 (3): 257--70.
\url{https://doi.org/10.1007/s10869-018-9547-8}.

\leavevmode\hypertarget{ref-Baumer2014}{}%
Baumer, Ben, Mine Cetinkaya-Rundel, Andrew Bray, Linda Loi, and Nicholas
J. Horton. 2014. {``{R Markdown: Integrating A Reproducible Analysis
Tool into Introductory Statistics}.''} \emph{Technology Innovations in
Statistics Education} 8 (1). \url{https://doi.org/10.5070/t581020118}.

\leavevmode\hypertarget{ref-Byers1989}{}%
Byers, J C, A Bittner, and S Hill. 1989. {``{Traditional and raw task
load index (TLX) correlations: Are paired comparisons necessary? In
A}.''} In.

\leavevmode\hypertarget{ref-Cetinkaya-Rundel2021}{}%
Çetinkaya-Rundel, Mine, and Victoria Ellison. 2021. {``{A Fresh Look at
Introductory Data Science}.''} \emph{Journal of Statistics and Data
Science Education} 29 (sup1): S16--26.
\url{https://doi.org/10.1080/10691898.2020.1804497}.

\leavevmode\hypertarget{ref-Cetinkaya-Rundel2018}{}%
Çetinkaya-Rundel, Mine, and Colin Rundel. 2018. {``{Infrastructure and
Tools for Teaching Computing Throughout the Statistical Curriculum}.''}
\emph{American Statistician} 72 (1): 58--65.
\url{https://doi.org/10.1080/00031305.2017.1397549}.

\leavevmode\hypertarget{ref-Donoho2017}{}%
Donoho, David. 2017. {``{50 Years of Data Science}.''} \emph{Journal of
Computational and Graphical Statistics} 26 (4): 745--66.
\url{https://doi.org/10.1080/10618600.2017.1384734}.

\leavevmode\hypertarget{ref-Estrellado2020}{}%
Estrellado, Ryan A., Emily A. Bovee, Jesse Mostipak, Joshua M.
Rosenberg, and Isabella C. Velásquez. 2020. \emph{{Data science in
education using R}}. London, England: Routledge.
\url{https://datascienceineducation.com/}.

\leavevmode\hypertarget{ref-Fiksel2019}{}%
Fiksel, Jacob, Leah R. Jager, Johannna S. Johanna S Hardin, and Margaret
A. Taub. 2019. {``{Using GitHub Classroom To Teach Statistics}.''}
\emph{Journal of Statistics Education} 27 (2): 110--19.
\url{https://doi.org/10.1080/10691898.2019.1617089}.

\leavevmode\hypertarget{ref-Freeman2014}{}%
Freeman, Scott, Sarah L. Eddy, Miles McDonough, Michelle K. Smith,
Nnadozie Okoroafor, Hannah Jordt, and Mary Pat Wenderoth. 2014.
{``{Active learning increases student performance in science,
engineering, and mathematics}.''} \emph{Proceedings of the National
Academy of Sciences of the United States of America} 111 (23): 8410--15.
\url{https://doi.org/10.1073/pnas.1319030111}.

\leavevmode\hypertarget{ref-Hart1988}{}%
Hart, Sandra G., and Lowell E. Staveland. 1988. {``{Development of
NASA-TLX (Task Load Index): Results of Empirical and Theoretical
Research}.''} \emph{Advances in Psychology} 52 (C): 139--83.
\url{https://doi.org/10.1016/S0166-4115(08)62386-9}.

\leavevmode\hypertarget{ref-Hsing2019}{}%
Hsing, Courtney, and Vanessa Gennarelli. 2019. {``{Using GitHub in the
Classroom Predicts Student Learning Outcomes and Classroom Experiences:
Findings from a Survey of Students and Teachers}.''} In
\emph{Proceedings of the 50th ACM Technical Symposium on Computer
Science Education}, 672--78. SIGCSE '19. New York, NY, USA: Association
for Computing Machinery. \url{https://doi.org/10.1145/3287324.3287460}.

\leavevmode\hypertarget{ref-Krathwohl2002}{}%
Krathwohl, David R. 2002. {``{A Revision of Bloom's Taxonomy: An
Overview}.''} \emph{Theory Into Practice} 41 (4): 212--18.
\url{https://doi.org/10.1207/s15430421tip4104_2}.

\leavevmode\hypertarget{ref-Larwin2011}{}%
Larwin, Karen, and David Larwin. 2011. {``{A Meta-Analysis Examining the
Impact of Computer-Assisted Instruction on Postsecondary Statistics
Education}.''} \emph{Journal of Research on Technology in Education} 43
(3): 253--78. \url{https://doi.org/10.1080/15391523.2011.10782572}.

\leavevmode\hypertarget{ref-Onwuegbuzie2003}{}%
Onwuegbuzie, Anthony J., and Vicki A. Wilson. 2003. {``{Statistics
Anxiety: Nature, etiology, antecedents, effects, and treatments--a
comprehensive review of the literature}.''} \emph{Teaching in Higher
Education} 8 (2): 195--209.
\url{https://doi.org/10.1080/1356251032000052447}.

\end{CSLReferences}

\end{document}
